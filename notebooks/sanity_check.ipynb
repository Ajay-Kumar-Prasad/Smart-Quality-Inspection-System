{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if Data is ready for Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes in MVTEC_AD dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/ajayyy/Desktop/Deep_Learning/Smart-Quality-Inspection-System/data/raw/MVTEC_AD/mvtec_anomaly_detection'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m root \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/ajayyy/Desktop/Deep_Learning/Smart-Quality-Inspection-System/data/raw/MVTEC_AD/mvtec_anomaly_detection\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m category \u001b[38;5;129;01min\u001b[39;00m root\u001b[38;5;241m.\u001b[39miterdir():\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m category\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/myvenv/lib/python3.10/pathlib.py:1017\u001b[0m, in \u001b[0;36mPath.iterdir\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21miterdir\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Iterate over the files in this directory.  Does not yield any\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;124;03m    result for the special paths '.' and '..'.\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1017\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1018\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m}:\n\u001b[1;32m   1019\u001b[0m             \u001b[38;5;66;03m# Yielding a path object for these makes little sense\u001b[39;00m\n\u001b[1;32m   1020\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/ajayyy/Desktop/Deep_Learning/Smart-Quality-Inspection-System/data/raw/MVTEC_AD/mvtec_anomaly_detection'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "root = Path(\"/Users/ajayyy/Desktop/Deep_Learning/Smart-Quality-Inspection-System/data/raw/MVTEC_AD/mvtec_anomaly_detection\")\n",
    "classes = set()\n",
    "for category in root.iterdir():\n",
    "    if not category.is_dir():\n",
    "        continue\n",
    "    test_dir = category / \"test\"\n",
    "    if test_dir.exists():\n",
    "        for defect_type in test_dir.iterdir():\n",
    "            if defect_type.is_dir() and defect_type.name != \"good\":\n",
    "                classes.add(defect_type.name)\n",
    "\n",
    "print(f\"Total defect classes: {len(classes)}\")\n",
    "print(sorted(classes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Koklektor Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: 2331/2333 defective\n",
      "TEST: 1004/1004 defective\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "root = Path(\"/Users/ajayyy/Desktop/Deep_Learning/Smart-Quality-Inspection-System/data/raw/KolektorSDD/KolektorSDD2\")\n",
    "train_dir = root / \"train\"\n",
    "test_dir = root / \"test\"\n",
    "\n",
    "def count_defects(folder):\n",
    "    defects = 0\n",
    "    total = 0\n",
    "    for img in folder.glob(\"*.png\"):\n",
    "        if img.name.endswith(\"_GT.png\"):\n",
    "            continue\n",
    "        total += 1\n",
    "        mask = folder / f\"{img.stem}_GT.png\"\n",
    "        if mask.exists():\n",
    "            defects += 1\n",
    "    return total, defects\n",
    "\n",
    "train_total, train_defects = count_defects(train_dir)\n",
    "test_total, test_defects = count_defects(test_dir)\n",
    "\n",
    "print(f\"TRAIN: {train_defects}/{train_total} defective\")\n",
    "print(f\"TEST: {test_defects}/{test_total} defective\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing category: bottle\n",
      "Processing category: cable\n",
      "Processing category: capsule\n",
      "Processing category: carpet\n",
      "Processing category: grid\n",
      "Processing category: hazelnut\n",
      "Processing category: leather\n",
      "Processing category: metal_nut\n",
      "Processing category: pill\n",
      "Processing category: screw\n",
      "Processing category: tile\n",
      "Processing category: toothbrush\n",
      "Processing category: transistor\n",
      "Processing category: wood\n",
      "Processing category: zipper\n",
      "\n",
      "Organization complete!\n",
      "Images and masks saved under: /Users/ajayyy/Desktop/Deep_Learning/Smart-Quality-Inspection-System/data/processed\n",
      "Metadata CSV: /Users/ajayyy/Desktop/Deep_Learning/Smart-Quality-Inspection-System/data/processed/metadata/mapping.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# ==============================\n",
    "# CONFIGURATION\n",
    "# ==============================\n",
    "RAW_DATASET_DIR = Path(\"/Users/ajayyy/Desktop/Deep_Learning/Smart-Quality-Inspection-System/data/raw/MVTEC_AD/mvtec_anomaly_detection\")  # <-- change this\n",
    "OUTPUT_DIR = Path(\"/Users/ajayyy/Desktop/Deep_Learning/Smart-Quality-Inspection-System/data/processed\")\n",
    "\n",
    "# Create output structure\n",
    "(OUTPUT_DIR / \"images/train\").mkdir(parents=True, exist_ok=True)\n",
    "(OUTPUT_DIR / \"images/val\").mkdir(parents=True, exist_ok=True)\n",
    "(OUTPUT_DIR / \"masks/val\").mkdir(parents=True, exist_ok=True)\n",
    "(OUTPUT_DIR / \"metadata\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "metadata = []\n",
    "\n",
    "# ==============================\n",
    "# ITERATE OVER ALL CATEGORIES\n",
    "# ==============================\n",
    "for category in sorted(os.listdir(RAW_DATASET_DIR)):\n",
    "    category_path = RAW_DATASET_DIR / category\n",
    "    if not category_path.is_dir():\n",
    "        continue\n",
    "\n",
    "    print(f\"Processing category: {category}\")\n",
    "\n",
    "    # --- TRAIN (GOOD IMAGES) ---\n",
    "    train_good_dir = category_path / \"train\" / \"good\"\n",
    "    if train_good_dir.exists():\n",
    "        for img_file in sorted(train_good_dir.glob(\"*\")):\n",
    "            new_name = f\"{category}_good_train_{img_file.name}\"\n",
    "            dest = OUTPUT_DIR / \"images/train\" / new_name\n",
    "            shutil.copy(img_file, dest)\n",
    "            metadata.append({\n",
    "                \"category\": category,\n",
    "                \"subset\": \"train\",\n",
    "                \"type\": \"good\",\n",
    "                \"image\": new_name,\n",
    "                \"mask\": None\n",
    "            })\n",
    "\n",
    "    # --- TEST (GOOD + DEFECTIVE) ---\n",
    "    test_dir = category_path / \"test\"\n",
    "    gt_dir = category_path / \"ground_truth\"\n",
    "\n",
    "    if test_dir.exists():\n",
    "        for defect_type in sorted(os.listdir(test_dir)):\n",
    "            defect_dir = test_dir / defect_type\n",
    "            if not defect_dir.is_dir():\n",
    "                continue\n",
    "\n",
    "            for img_file in sorted(defect_dir.glob(\"*\")):\n",
    "                new_name = f\"{category}_{defect_type}_{img_file.name}\"\n",
    "                dest = OUTPUT_DIR / \"images/val\" / new_name\n",
    "                shutil.copy(img_file, dest)\n",
    "\n",
    "                mask_file = None\n",
    "                if defect_type != \"good\":  # Only defective images have masks\n",
    "                    mask_dir = gt_dir / defect_type\n",
    "                    if mask_dir.exists():\n",
    "                        base_name = img_file.stem\n",
    "                        possible_masks = list(mask_dir.glob(f\"{base_name}*\"))\n",
    "                        if possible_masks:\n",
    "                            mask_file = possible_masks[0]\n",
    "                            new_mask_name = f\"{category}_{defect_type}_{mask_file.name}\"\n",
    "                            mask_dest = OUTPUT_DIR / \"masks/val\" / new_mask_name\n",
    "                            shutil.copy(mask_file, mask_dest)\n",
    "                            mask_file = new_mask_name\n",
    "\n",
    "                metadata.append({\n",
    "                    \"category\": category,\n",
    "                    \"subset\": \"val\",\n",
    "                    \"type\": defect_type,\n",
    "                    \"image\": new_name,\n",
    "                    \"mask\": mask_file\n",
    "                })\n",
    "\n",
    "# ==============================\n",
    "# SAVE METADATA\n",
    "# ==============================\n",
    "df = pd.DataFrame(metadata)\n",
    "df.to_csv(OUTPUT_DIR / \"metadata\" / \"mapping.csv\", index=False)\n",
    "print(\"\\nOrganization complete!\")\n",
    "print(f\"Images and masks saved under: {OUTPUT_DIR}\")\n",
    "print(f\"Metadata CSV: {OUTPUT_DIR / 'metadata/mapping.csv'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"/Users/ajayyy/Desktop/Deep_Learning/Smart-Quality-Inspection-System/data/processed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verify every defective image has a corresponding mask**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " All defective images have corresponding masks!\n"
     ]
    }
   ],
   "source": [
    "defective_missing_masks = []\n",
    "\n",
    "for category in categories:\n",
    "    gt_path = os.path.join(DATASET_PATH, category, \"ground_truth\")\n",
    "    test_path = os.path.join(DATASET_PATH, category, \"test\")\n",
    "    if not os.path.exists(gt_path):\n",
    "        continue\n",
    "\n",
    "    for defect_type in os.listdir(gt_path):\n",
    "        gt_files = sorted(os.listdir(os.path.join(gt_path, defect_type)))\n",
    "        test_files = sorted(os.listdir(os.path.join(test_path, defect_type)))\n",
    "\n",
    "        gt_basenames = [os.path.splitext(f)[0] for f in gt_files]\n",
    "        test_basenames = [os.path.splitext(f)[0] for f in test_files]\n",
    "\n",
    "        missing = [f for f in test_basenames if f not in gt_basenames]\n",
    "        if missing:\n",
    "            defective_missing_masks.extend([(category, defect_type, m) for m in missing])\n",
    "\n",
    "if defective_missing_masks:\n",
    "    print(\"\\n⚠️ Missing masks for these images:\")\n",
    "    for item in defective_missing_masks[:10]:\n",
    "        print(item)\n",
    "else:\n",
    "    print(\"\\n All defective images have corresponding masks!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## checking labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1258 label files.\n",
      "✓ Visualized: carpet_color_003.png\n",
      "✓ Visualized: tile_rough_006.png\n",
      "✓ Visualized: wood_combined_005.png\n",
      "✓ Visualized: zipper_fabric_border_014.png\n",
      "✓ Visualized: bottle_broken_large_001.png\n",
      "✓ Visualized: hazelnut_hole_008.png\n",
      "✓ Visualized: wood_color_002.png\n",
      "✓ Visualized: capsule_squeeze_008.png\n",
      "✓ Visualized: zipper_fabric_interior_011.png\n",
      "✓ Visualized: zipper_rough_016.png\n",
      "\n",
      "Sanity check complete! Labeled samples saved to:\n",
      "/Users/ajayyy/Desktop/Deep_Learning/Smart-Quality-Inspection-System/data/processed/sanity_check_outputs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "# === PATHS ===\n",
    "base_dir = \"/Users/ajayyy/Desktop/Deep_Learning/Smart-Quality-Inspection-System/data/processed\"\n",
    "images_dir = os.path.join(base_dir, \"images/val\")\n",
    "labels_dir = os.path.join(base_dir, \"labels/val\")\n",
    "output_dir = os.path.join(base_dir, \"sanity_check_outputs\")\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "num_samples = 10 \n",
    "\n",
    "# === FUNCTION TO DRAW BOXES ===\n",
    "def draw_yolo_boxes(img_path, label_path, save_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        return False\n",
    "\n",
    "    h, w = img.shape[:2]\n",
    "    if not os.path.exists(label_path):\n",
    "        return False\n",
    "\n",
    "    with open(label_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) != 5:\n",
    "            continue\n",
    "        cls, x, y, bw, bh = map(float, parts)\n",
    "        x1 = int((x - bw / 2) * w)\n",
    "        y1 = int((y - bh / 2) * h)\n",
    "        x2 = int((x + bw / 2) * w)\n",
    "        y2 = int((y + bh / 2) * h)\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "        cv2.putText(img, f\"defect\", (x1, y1 - 5),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "\n",
    "    cv2.imwrite(save_path, img)\n",
    "    return True\n",
    "\n",
    "# === RANDOMLY CHECK SOME LABELS ===\n",
    "label_files = [f for f in os.listdir(labels_dir) if f.endswith(\".txt\")]\n",
    "print(f\"Found {len(label_files)} label files.\")\n",
    "\n",
    "sample_files = random.sample(label_files, min(num_samples, len(label_files)))\n",
    "\n",
    "for lf in sample_files:\n",
    "    label_path = os.path.join(labels_dir, lf)\n",
    "    img_name = lf.replace(\".txt\", \".png\")\n",
    "    img_path = os.path.join(images_dir, img_name)\n",
    "    if not os.path.exists(img_path):\n",
    "        img_name = lf.replace(\".txt\", \".jpg\")\n",
    "        img_path = os.path.join(images_dir, img_name)\n",
    "        if not os.path.exists(img_path):\n",
    "            continue\n",
    "    save_path = os.path.join(output_dir, img_name)\n",
    "    success = draw_yolo_boxes(img_path, label_path, save_path)\n",
    "    if success:\n",
    "        print(f\"✓ Visualized: {img_name}\")\n",
    "    else:\n",
    "        print(f\"⚠️ Skipped: {img_name}\")\n",
    "\n",
    "print(f\"\\nSanity check complete! Labeled samples saved to:\\n{output_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organising Kolektor Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Organizing train: 100%|██████████| 4878/4878 [00:00<00:00, 93541.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train done — 4878 files processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Organizing val: 100%|██████████| 2082/2082 [00:00<00:00, 161456.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val done — 2082 files processed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "\n",
    "base_dir = \"/Users/ajayyy/Desktop/Deep_Learning/Smart-Quality-Inspection-System/data\"\n",
    "raw_dir = os.path.join(base_dir, \"raw/KolektorSDD/KolektorSDD2\")\n",
    "processed_dir = os.path.join(base_dir, \"processed\")\n",
    "\n",
    "images_dir = os.path.join(processed_dir, \"images2\")\n",
    "masks_dir = os.path.join(processed_dir, \"masks2\")\n",
    "os.makedirs(images_dir, exist_ok=True)\n",
    "os.makedirs(masks_dir, exist_ok=True)\n",
    "\n",
    "def copy_file(src, dst):\n",
    "    try:\n",
    "        shutil.copy2(src, dst)\n",
    "    except Exception as e:\n",
    "        print(f\"Error copying {src}: {e}\")\n",
    "\n",
    "def organize_kolektor(raw_split, split_name):\n",
    "    split_path = os.path.join(raw_dir, raw_split)\n",
    "    img_out = os.path.join(images_dir, split_name)\n",
    "    mask_out = os.path.join(masks_dir, split_name)\n",
    "    os.makedirs(img_out, exist_ok=True)\n",
    "    os.makedirs(mask_out, exist_ok=True)\n",
    "\n",
    "    files = [f for f in os.listdir(split_path) if f.lower().endswith((\".png\", \".jpg\"))]\n",
    "\n",
    "    tasks = []\n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        for f in tqdm(files, desc=f\"Organizing {split_name}\"):\n",
    "            src = os.path.join(split_path, f)\n",
    "            if \"_gt\" in f.lower():\n",
    "                dst = os.path.join(mask_out, f.replace(\"_GT\", \"\").replace(\"_gt\", \"\"))\n",
    "            else:\n",
    "                dst = os.path.join(img_out, f)\n",
    "            tasks.append(executor.submit(copy_file, src, dst))\n",
    "\n",
    "        for task in as_completed(tasks):\n",
    "            _ = task.result()\n",
    "\n",
    "    print(f\"{split_name} done — {len(files)} files processed.\")\n",
    "\n",
    "organize_kolektor(\"train\", \"train\")\n",
    "organize_kolektor(\"test\", \"val\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train images: 2439\n",
      "train masks: 2439\n",
      "val images: 1041\n",
      "val masks: 1041\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"train images:\", len(os.listdir(\"/Users/ajayyy/Desktop/Deep_Learning/Smart-Quality-Inspection-System/data/processed/images2/train\")))\n",
    "print(\"train masks:\", len(os.listdir(\"/Users/ajayyy/Desktop/Deep_Learning/Smart-Quality-Inspection-System/data/processed/masks2/train\")))\n",
    "print(\"val images:\", len(os.listdir(\"/Users/ajayyy/Desktop/Deep_Learning/Smart-Quality-Inspection-System/data/processed/images2/val\")))\n",
    "print(\"val masks:\", len(os.listdir(\"/Users/ajayyy/Desktop/Deep_Learning/Smart-Quality-Inspection-System/data/processed/masks2/val\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 147 label files.\n",
      " Visualized: 20378_aug1769.png\n",
      " Visualized: 20821.png\n",
      " Visualized: 20669.png\n",
      " Visualized: 20172_aug8612.png\n",
      " Visualized: 20632_aug4385.png\n",
      " Visualized: 20682_aug6115.png\n",
      " Visualized: 20099.png\n",
      " Visualized: 20056.png\n",
      " Visualized: 20587.png\n",
      " Visualized: 20772.png\n",
      "\n",
      "Sanity check complete! Labeled samples saved to:\n",
      "/Users/ajayyy/Desktop/Deep_Learning/Smart-Quality-Inspection-System/data/processed/sanity_check_outputs2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "# === PATHS ===\n",
    "base_dir = \"/Users/ajayyy/Desktop/Deep_Learning/Smart-Quality-Inspection-System/data/processed\"\n",
    "images_dir = os.path.join(base_dir, \"images2/val\")\n",
    "labels_dir = os.path.join(base_dir, \"labels2/val\")\n",
    "output_dir = os.path.join(base_dir, \"sanity_check_outputs2\")\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "num_samples = 10 \n",
    "\n",
    "# === FUNCTION TO DRAW BOXES ===\n",
    "def draw_yolo_boxes(img_path, label_path, save_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        return False\n",
    "\n",
    "    h, w = img.shape[:2]\n",
    "    if not os.path.exists(label_path):\n",
    "        return False\n",
    "\n",
    "    with open(label_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) != 5:\n",
    "            continue\n",
    "        cls, x, y, bw, bh = map(float, parts)\n",
    "        x1 = int((x - bw / 2) * w)\n",
    "        y1 = int((y - bh / 2) * h)\n",
    "        x2 = int((x + bw / 2) * w)\n",
    "        y2 = int((y + bh / 2) * h)\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "        cv2.putText(img, f\"defect\", (x1, y1 - 5),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "\n",
    "    cv2.imwrite(save_path, img)\n",
    "    return True\n",
    "\n",
    "# === RANDOMLY CHECK SOME LABELS ===\n",
    "label_files = [f for f in os.listdir(labels_dir) if f.endswith(\".txt\")]\n",
    "print(f\"Found {len(label_files)} label files.\")\n",
    "\n",
    "sample_files = random.sample(label_files, min(num_samples, len(label_files)))\n",
    "\n",
    "for lf in sample_files:\n",
    "    label_path = os.path.join(labels_dir, lf)\n",
    "    img_name = lf.replace(\".txt\", \".png\")\n",
    "    img_path = os.path.join(images_dir, img_name)\n",
    "    if not os.path.exists(img_path):\n",
    "        img_name = lf.replace(\".txt\", \".jpg\")\n",
    "        img_path = os.path.join(images_dir, img_name)\n",
    "        if not os.path.exists(img_path):\n",
    "            continue\n",
    "    save_path = os.path.join(output_dir, img_name)\n",
    "    success = draw_yolo_boxes(img_path, label_path, save_path)\n",
    "    if success:\n",
    "        print(f\" Visualized: {img_name}\")\n",
    "    else:\n",
    "        print(f\"Skipped: {img_name}\")\n",
    "\n",
    "print(f\"\\nSanity check complete! Labeled samples saved to:\\n{output_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEU-DET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TRAIN SPLIT ===\n",
      "Total images: 1440\n",
      "Total labels: 1440\n",
      "Images without labels: 0\n",
      "Labels without images: 0\n",
      "\n",
      "=== VALIDATION SPLIT ===\n",
      "Total images: 360\n",
      "Total labels: 360\n",
      "Images without labels: 0\n",
      "Labels without images: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "base_dir = \"/Users/ajayyy/Desktop/Deep_Learning/Smart-Quality-Inspection-System/data/raw/NEU-DET\"\n",
    "splits = [\"train\", \"validation\"]\n",
    "\n",
    "for split in splits:\n",
    "    images_dir = os.path.join(base_dir, split, \"images\")\n",
    "    labels_dir = os.path.join(base_dir, \"labels\", split)\n",
    "\n",
    "    # Collect all image filenames (without extension), recursively through class subfolders\n",
    "    image_files = []\n",
    "    for root, _, files in os.walk(images_dir):\n",
    "        for f in files:\n",
    "            if f.lower().endswith(('.jpg', '.png')):\n",
    "                image_files.append(os.path.splitext(f)[0])\n",
    "\n",
    "    # Collect all label filenames (without extension)\n",
    "    label_files = []\n",
    "    if os.path.exists(labels_dir):\n",
    "        for root, _, files in os.walk(labels_dir):\n",
    "            for f in files:\n",
    "                if f.endswith('.txt'):\n",
    "                    label_files.append(os.path.splitext(f)[0])\n",
    "    else:\n",
    "        print(f\" Labels folder does not exist for split: {split}\")\n",
    "\n",
    "    image_set = set(image_files)\n",
    "    label_set = set(label_files)\n",
    "\n",
    "    missing_labels = image_set - label_set\n",
    "    extra_labels = label_set - image_set\n",
    "\n",
    "    print(f\"\\n=== {split.upper()} SPLIT ===\")\n",
    "    print(f\"Total images: {len(image_files)}\")\n",
    "    print(f\"Total labels: {len(label_files)}\")\n",
    "    print(f\"Images without labels: {len(missing_labels)}\")\n",
    "    print(f\"Labels without images: {len(extra_labels)}\")\n",
    "\n",
    "    if missing_labels:\n",
    "        print(\"Missing labels for images:\", sorted(missing_labels))\n",
    "    if extra_labels:\n",
    "        print(\"Labels with no corresponding images:\", sorted(extra_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Visualized: pitted_surface_218.jpg\n",
      " Visualized: inclusion_146.jpg\n",
      " Visualized: pitted_surface_207.jpg\n",
      " Visualized: scratches_66.jpg\n",
      " Visualized: inclusion_107.jpg\n",
      " Visualized: pitted_surface_259.jpg\n",
      " Visualized: pitted_surface_272.jpg\n",
      " Visualized: scratches_255.jpg\n",
      " Visualized: pitted_surface_257.jpg\n",
      " Visualized: patches_281.jpg\n",
      "\n",
      "Bounding box visualization complete! Check the folder:\n",
      "/Users/ajayyy/Desktop/Deep_Learning/Smart-Quality-Inspection-System/data/raw/NEU-DET/bbox_visuals\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "# === PATHS ===\n",
    "base_dir = \"/Users/ajayyy/Desktop/Deep_Learning/Smart-Quality-Inspection-System/data/raw/NEU-DET\"\n",
    "splits = [\"train\", \"validation\"]\n",
    "output_dir = os.path.join(base_dir, \"bbox_visuals\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "num_samples = 5  # images per split\n",
    "\n",
    "# === FUNCTION TO DRAW YOLO BOXES ===\n",
    "def draw_yolo_boxes(img_path, label_path, save_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        return False\n",
    "    h, w = img.shape[:2]\n",
    "    if not os.path.exists(label_path):\n",
    "        return False\n",
    "    with open(label_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    for line in lines:\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) != 5:\n",
    "            continue\n",
    "        cls_id, x, y, bw, bh = map(float, parts)\n",
    "        x1 = int((x - bw / 2) * w)\n",
    "        y1 = int((y - bh / 2) * h)\n",
    "        x2 = int((x + bw / 2) * w)\n",
    "        y2 = int((y + bh / 2) * h)\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "        cv2.putText(img, str(int(cls_id)), (x1, y1 - 5),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "    cv2.imwrite(save_path, img)\n",
    "    return True\n",
    "\n",
    "# === HELPER FUNCTION TO FIND IMAGE RECURSIVELY ===\n",
    "def find_image(image_name, search_dir):\n",
    "    for root, _, files in os.walk(search_dir):\n",
    "        for file in files:\n",
    "            if file.startswith(image_name):\n",
    "                return os.path.join(root, file)\n",
    "    return None\n",
    "\n",
    "# === VISUALIZE RANDOM SAMPLES ===\n",
    "for split in splits:\n",
    "    images_dir = os.path.join(base_dir, split)\n",
    "    labels_dir = os.path.join(base_dir, \"labels\", split)\n",
    "    split_output_dir = os.path.join(output_dir, split)\n",
    "    os.makedirs(split_output_dir, exist_ok=True)\n",
    "\n",
    "    label_files = [f for f in os.listdir(labels_dir) if f.endswith(\".txt\")]\n",
    "    sample_files = random.sample(label_files, min(num_samples, len(label_files)))\n",
    "\n",
    "    for lf in sample_files:\n",
    "        label_path = os.path.join(labels_dir, lf)\n",
    "        img_name = lf.replace(\".txt\", \"\")\n",
    "\n",
    "        img_path = find_image(img_name, images_dir)\n",
    "        if img_path is None:\n",
    "            print(f\"Image not found for label: {lf}\")\n",
    "            continue\n",
    "\n",
    "        save_path = os.path.join(split_output_dir, os.path.basename(img_path))\n",
    "        success = draw_yolo_boxes(img_path, label_path, save_path)\n",
    "        if success:\n",
    "            print(f\" Visualized: {os.path.basename(img_path)}\")\n",
    "        else:\n",
    "            print(f\"Skipped: {os.path.basename(img_path)}\")\n",
    "\n",
    "print(f\"\\nBounding box visualization complete! Check the folder:\\n{output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.12.0.88-cp37-abi3-macosx_13_0_arm64.whl.metadata (19 kB)\n",
      "Collecting numpy<2.3.0,>=2 (from opencv-python)\n",
      "  Using cached numpy-2.2.6-cp310-cp310-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Using cached opencv_python-4.12.0.88-cp37-abi3-macosx_13_0_arm64.whl (37.9 MB)\n",
      "Using cached numpy-2.2.6-cp310-cp310-macosx_14_0_arm64.whl (5.3 MB)\n",
      "Installing collected packages: numpy, opencv-python\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [opencv-python]0m [opencv-python]\n",
      "\u001b[1A\u001b[2KSuccessfully installed numpy-2.2.6 opencv-python-4.12.0.88\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Analyzing split: TRAIN ===\n",
      "Found 10907 images under /Users/ajayyy/Desktop/Deep_Learning/Smart-Quality-Inspection/data/images/train\n",
      "Missing label files: 0\n",
      "Empty label files: 5574\n",
      "Bad label lines: 8832\n",
      "Total boxes: 3336\n",
      "Avg boxes per image: 0.63\n",
      "Box area stats (normalized): min=0.000242, mean=0.155360, max=0.990025\n",
      "\n",
      "Top 10 most common image sizes (WxH):\n",
      "  200x200: 4980 images\n",
      "  512x512: 353 images\n",
      "\n",
      "Class distribution:\n",
      "  class 0: 3336 (100.00%)\n",
      "\n",
      "Outlier boxes: too small=0, too large=189\n",
      "========================================\n",
      "\n",
      "=== Analyzing split: VAL ===\n",
      "Found 3126 images under /Users/ajayyy/Desktop/Deep_Learning/Smart-Quality-Inspection/data/images/val\n",
      "Missing label files: 0\n",
      "Empty label files: 1362\n",
      "Bad label lines: 0\n",
      "Total boxes: 2886\n",
      "Avg boxes per image: 1.64\n",
      "Box area stats (normalized): min=0.000076, mean=0.097044, max=0.974609\n",
      "\n",
      "Top 10 most common image sizes (WxH):\n",
      "  512x512: 1404 images\n",
      "  200x200: 360 images\n",
      "\n",
      "Class distribution:\n",
      "  class 0: 2886 (100.00%)\n",
      "\n",
      "Outlier boxes: too small=8, too large=110\n",
      "========================================\n",
      "\n",
      "=== SUMMARY ===\n",
      "TRAIN: 10907 imgs, 5574 empty, 3336 boxes, mean boxes/img 0.63\n",
      "VAL: 3126 imgs, 1362 empty, 2886 boxes, mean boxes/img 1.64\n",
      "\n",
      "Done. Your dataset now has no excuses left.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from collections import Counter, defaultdict\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "ROOT_IMG = Path(\"/Users/ajayyy/Desktop/Deep_Learning/Smart-Quality-Inspection/data/images\")\n",
    "ROOT_LAB = Path(\"/Users/ajayyy/Desktop/Deep_Learning/Smart-Quality-Inspection/data/labels\")\n",
    "EXTS = [\".jpg\", \".png\", \".jpeg\", \".bmp\", \".tif\"]\n",
    "\n",
    "def find_images(root):\n",
    "    imgs = []\n",
    "    for p in root.rglob(\"*\"):\n",
    "        if p.suffix.lower() in EXTS:\n",
    "            imgs.append(p)\n",
    "    return imgs\n",
    "\n",
    "def corresponding_label(img_path):\n",
    "    rel = img_path.relative_to(ROOT_IMG)\n",
    "    return ROOT_LAB / rel.with_suffix(\".txt\")\n",
    "\n",
    "def read_label_file(label_path):\n",
    "    if not label_path.exists():\n",
    "        return None\n",
    "    lines = [l.strip() for l in label_path.read_text().splitlines() if l.strip()]\n",
    "    return lines\n",
    "\n",
    "def check_yolo_line(line):\n",
    "    parts = line.split()\n",
    "    if len(parts) < 5:\n",
    "        return None\n",
    "    try:\n",
    "        cls = int(parts[0])\n",
    "        x, y, w, h = map(float, parts[1:5])\n",
    "    except:\n",
    "        return None\n",
    "    if not (0 <= x <= 1 and 0 <= y <= 1 and 0 <= w <= 1 and 0 <= h <= 1):\n",
    "        return None\n",
    "    area = w * h\n",
    "    return {\"cls\": cls, \"area\": area}\n",
    "\n",
    "def analyze_dataset():\n",
    "    splits = [\"train\", \"val\"]\n",
    "    summary = {}\n",
    "\n",
    "    for split in splits:\n",
    "        print(f\"\\n=== Analyzing split: {split.upper()} ===\")\n",
    "        img_dir = ROOT_IMG / split\n",
    "        lab_dir = ROOT_LAB / split\n",
    "\n",
    "        imgs = find_images(img_dir)\n",
    "        print(f\"Found {len(imgs)} images under {img_dir}\")\n",
    "\n",
    "        empty_labels = 0\n",
    "        missing_labels = 0\n",
    "        bad_lines = 0\n",
    "        total_boxes = 0\n",
    "        class_counts = Counter()\n",
    "        box_areas = []\n",
    "        img_shapes = Counter()\n",
    "        boxes_per_img = []\n",
    "\n",
    "        for img_path in imgs:\n",
    "            lab_path = corresponding_label(img_path)\n",
    "            lines = read_label_file(lab_path)\n",
    "            if lines is None:\n",
    "                missing_labels += 1\n",
    "                continue\n",
    "            if len(lines) == 0:\n",
    "                empty_labels += 1\n",
    "                continue\n",
    "\n",
    "            img = cv2.imread(str(img_path))\n",
    "            if img is not None:\n",
    "                h, w = img.shape[:2]\n",
    "                img_shapes[(w, h)] += 1\n",
    "\n",
    "            valid_boxes = 0\n",
    "            for line in lines:\n",
    "                res = check_yolo_line(line)\n",
    "                if not res:\n",
    "                    bad_lines += 1\n",
    "                    continue\n",
    "                class_counts[res[\"cls\"]] += 1\n",
    "                box_areas.append(res[\"area\"])\n",
    "                valid_boxes += 1\n",
    "            total_boxes += valid_boxes\n",
    "            boxes_per_img.append(valid_boxes)\n",
    "\n",
    "        # Compute stats\n",
    "        mean_boxes = np.mean(boxes_per_img) if boxes_per_img else 0\n",
    "        mean_area = np.mean(box_areas) if box_areas else 0\n",
    "        min_area = np.min(box_areas) if box_areas else 0\n",
    "        max_area = np.max(box_areas) if box_areas else 0\n",
    "\n",
    "        print(f\"Missing label files: {missing_labels}\")\n",
    "        print(f\"Empty label files: {empty_labels}\")\n",
    "        print(f\"Bad label lines: {bad_lines}\")\n",
    "        print(f\"Total boxes: {total_boxes}\")\n",
    "        print(f\"Avg boxes per image: {mean_boxes:.2f}\")\n",
    "        print(f\"Box area stats (normalized): min={min_area:.6f}, mean={mean_area:.6f}, max={max_area:.6f}\")\n",
    "        print(\"\\nTop 10 most common image sizes (WxH):\")\n",
    "        for (w, h), c in img_shapes.most_common(10):\n",
    "            print(f\"  {w}x{h}: {c} images\")\n",
    "\n",
    "        print(\"\\nClass distribution:\")\n",
    "        total_labels = sum(class_counts.values())\n",
    "        for cls, cnt in class_counts.most_common():\n",
    "            pct = (cnt / total_labels * 100) if total_labels else 0\n",
    "            print(f\"  class {cls}: {cnt} ({pct:.2f}%)\")\n",
    "\n",
    "        outliers_small = sum(a < 0.0001 for a in box_areas)\n",
    "        outliers_large = sum(a > 0.5 for a in box_areas)\n",
    "        print(f\"\\nOutlier boxes: too small={outliers_small}, too large={outliers_large}\")\n",
    "        print(\"=\" * 40)\n",
    "\n",
    "        summary[split] = {\n",
    "            \"images\": len(imgs),\n",
    "            \"missing\": missing_labels,\n",
    "            \"empty\": empty_labels,\n",
    "            \"total_boxes\": total_boxes,\n",
    "            \"mean_boxes\": mean_boxes,\n",
    "            \"classes\": dict(class_counts)\n",
    "        }\n",
    "\n",
    "    print(\"\\n=== SUMMARY ===\")\n",
    "    for k, v in summary.items():\n",
    "        print(f\"{k.upper()}: {v['images']} imgs, {v['empty']} empty, {v['total_boxes']} boxes, mean boxes/img {v['mean_boxes']:.2f}\")\n",
    "    print(\"\\nDone. Your dataset now has no excuses left.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    analyze_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/facebookresearch/segment-anything.git (from -r /Users/ajayyy/Desktop/Deep_Learning/Smart-Quality-Inspection/requirements.txt (line 6))\n",
      "  Cloning https://github.com/facebookresearch/segment-anything.git to /private/var/folders/sg/mjc3zgxd0xggmd4mpy2fkrq80000gn/T/pip-req-build-aevqx5d1\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/segment-anything.git /private/var/folders/sg/mjc3zgxd0xggmd4mpy2fkrq80000gn/T/pip-req-build-aevqx5d1\n",
      "  Resolved https://github.com/facebookresearch/segment-anything.git to commit dca509fe793f601edb92606367a655c15ac00fdf\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting torch (from -r /Users/ajayyy/Desktop/Deep_Learning/Smart-Quality-Inspection/requirements.txt (line 1))\n",
      "  Downloading torch-2.9.0-cp310-none-macosx_11_0_arm64.whl.metadata (30 kB)\n",
      "Collecting torchvision (from -r /Users/ajayyy/Desktop/Deep_Learning/Smart-Quality-Inspection/requirements.txt (line 2))\n",
      "  Downloading torchvision-0.24.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (5.9 kB)\n",
      "Collecting ultralytics (from -r /Users/ajayyy/Desktop/Deep_Learning/Smart-Quality-Inspection/requirements.txt (line 3))\n",
      "  Using cached ultralytics-8.3.226-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: opencv-python in /Applications/anaconda3/envs/myvenv/lib/python3.10/site-packages (from -r /Users/ajayyy/Desktop/Deep_Learning/Smart-Quality-Inspection/requirements.txt (line 4)) (4.12.0.88)\n",
      "Collecting segment-anything (from -r /Users/ajayyy/Desktop/Deep_Learning/Smart-Quality-Inspection/requirements.txt (line 5))\n",
      "  Using cached segment_anything-1.0-py3-none-any.whl.metadata (487 bytes)\n",
      "Collecting fastapi (from -r /Users/ajayyy/Desktop/Deep_Learning/Smart-Quality-Inspection/requirements.txt (line 7))\n",
      "  Downloading fastapi-0.121.0-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting uvicorn (from -r /Users/ajayyy/Desktop/Deep_Learning/Smart-Quality-Inspection/requirements.txt (line 8))\n",
      "  Using cached uvicorn-0.38.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting streamlit (from -r /Users/ajayyy/Desktop/Deep_Learning/Smart-Quality-Inspection/requirements.txt (line 9))\n",
      "  Using cached streamlit-1.51.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting mlflow (from -r /Users/ajayyy/Desktop/Deep_Learning/Smart-Quality-Inspection/requirements.txt (line 10))\n",
      "  Downloading mlflow-3.6.0-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting boto3 (from -r /Users/ajayyy/Desktop/Deep_Learning/Smart-Quality-Inspection/requirements.txt (line 11))\n",
      "  Downloading boto3-1.40.69-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting docker (from -r /Users/ajayyy/Desktop/Deep_Learning/Smart-Quality-Inspection/requirements.txt (line 12))\n",
      "  Using cached docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting psycopg2 (from -r /Users/ajayyy/Desktop/Deep_Learning/Smart-Quality-Inspection/requirements.txt (line 13))\n",
      "  Using cached psycopg2-2.9.11.tar.gz (379 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[36 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m /Applications/anaconda3/envs/myvenv/lib/python3.10/site-packages/setuptools/dist.py:759: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         Please consider removing the following classifiers in favor of a SPDX license expression:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         License :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   self._finalize_license_expression()\n",
      "  \u001b[31m   \u001b[0m running egg_info\n",
      "  \u001b[31m   \u001b[0m creating /private/var/folders/sg/mjc3zgxd0xggmd4mpy2fkrq80000gn/T/pip-pip-egg-info-mfd2vujw/psycopg2.egg-info\n",
      "  \u001b[31m   \u001b[0m writing /private/var/folders/sg/mjc3zgxd0xggmd4mpy2fkrq80000gn/T/pip-pip-egg-info-mfd2vujw/psycopg2.egg-info/PKG-INFO\n",
      "  \u001b[31m   \u001b[0m writing dependency_links to /private/var/folders/sg/mjc3zgxd0xggmd4mpy2fkrq80000gn/T/pip-pip-egg-info-mfd2vujw/psycopg2.egg-info/dependency_links.txt\n",
      "  \u001b[31m   \u001b[0m writing top-level names to /private/var/folders/sg/mjc3zgxd0xggmd4mpy2fkrq80000gn/T/pip-pip-egg-info-mfd2vujw/psycopg2.egg-info/top_level.txt\n",
      "  \u001b[31m   \u001b[0m writing manifest file '/private/var/folders/sg/mjc3zgxd0xggmd4mpy2fkrq80000gn/T/pip-pip-egg-info-mfd2vujw/psycopg2.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Error: pg_config executable not found.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m pg_config is required to build psycopg2 from source.  Please add the directory\n",
      "  \u001b[31m   \u001b[0m containing pg_config to the $PATH or specify the full executable path with the\n",
      "  \u001b[31m   \u001b[0m option:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m     python setup.py build_ext --pg-config /path/to/pg_config build ...\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m or with the pg_config option in 'setup.cfg'.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m If you prefer to avoid building psycopg2 from source, please install the PyPI\n",
      "  \u001b[31m   \u001b[0m 'psycopg2-binary' package instead.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m For further information please check the 'doc/src/install.rst' file (also at\n",
      "  \u001b[31m   \u001b[0m <https://www.psycopg.org/docs/install.html>).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r /Users/ajayyy/Desktop/Deep_Learning/Smart-Quality-Inspection/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting albumentations\n",
      "  Using cached albumentations-2.0.8-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: numpy>=1.24.4 in /Applications/anaconda3/envs/myvenv/lib/python3.10/site-packages (from albumentations) (2.2.6)\n",
      "Collecting scipy>=1.10.0 (from albumentations)\n",
      "  Using cached scipy-1.15.3-cp310-cp310-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "Collecting PyYAML (from albumentations)\n",
      "  Downloading pyyaml-6.0.3-cp310-cp310-macosx_11_0_arm64.whl.metadata (2.4 kB)\n",
      "Collecting pydantic>=2.9.2 (from albumentations)\n",
      "  Downloading pydantic-2.12.4-py3-none-any.whl.metadata (89 kB)\n",
      "Collecting albucore==0.0.24 (from albumentations)\n",
      "  Using cached albucore-0.0.24-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting opencv-python-headless>=4.9.0.80 (from albumentations)\n",
      "  Using cached opencv_python_headless-4.12.0.88-cp37-abi3-macosx_13_0_arm64.whl.metadata (19 kB)\n",
      "Collecting stringzilla>=3.10.4 (from albucore==0.0.24->albumentations)\n",
      "  Downloading stringzilla-4.2.3-cp310-cp310-macosx_11_0_arm64.whl.metadata (110 kB)\n",
      "Collecting simsimd>=5.9.2 (from albucore==0.0.24->albumentations)\n",
      "  Downloading simsimd-6.5.3-cp310-cp310-macosx_11_0_arm64.whl.metadata (70 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.9.2->albumentations)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic>=2.9.2->albumentations)\n",
      "  Downloading pydantic_core-2.41.5-cp310-cp310-macosx_11_0_arm64.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in /Applications/anaconda3/envs/myvenv/lib/python3.10/site-packages (from pydantic>=2.9.2->albumentations) (4.15.0)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic>=2.9.2->albumentations)\n",
      "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Using cached albumentations-2.0.8-py3-none-any.whl (369 kB)\n",
      "Using cached albucore-0.0.24-py3-none-any.whl (15 kB)\n",
      "Using cached opencv_python_headless-4.12.0.88-cp37-abi3-macosx_13_0_arm64.whl (37.9 MB)\n",
      "Downloading pydantic-2.12.4-py3-none-any.whl (463 kB)\n",
      "Downloading pydantic_core-2.41.5-cp310-cp310-macosx_11_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached scipy-1.15.3-cp310-cp310-macosx_14_0_arm64.whl (22.4 MB)\n",
      "Downloading simsimd-6.5.3-cp310-cp310-macosx_11_0_arm64.whl (134 kB)\n",
      "Downloading stringzilla-4.2.3-cp310-cp310-macosx_11_0_arm64.whl (133 kB)\n",
      "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Downloading pyyaml-6.0.3-cp310-cp310-macosx_11_0_arm64.whl (174 kB)\n",
      "Installing collected packages: simsimd, typing-inspection, stringzilla, scipy, PyYAML, pydantic-core, opencv-python-headless, annotated-types, pydantic, albucore, albumentations\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/11\u001b[0m [albumentations]m [albumentations]eadless]\n",
      "\u001b[1A\u001b[2KSuccessfully installed PyYAML-6.0.3 albucore-0.0.24 albumentations-2.0.8 annotated-types-0.7.0 opencv-python-headless-4.12.0.88 pydantic-2.12.4 pydantic-core-2.41.5 scipy-1.15.3 simsimd-6.5.3 stringzilla-4.2.3 typing-inspection-0.4.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install albumentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balancing the training dataset to 60:40 non-defect to defect ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== BEFORE AUGMENTATION ===\n",
      "Good images:   5574\n",
      "Defect images: 1598\n",
      "\n",
      "Target defect count for 60% ratio: 3716\n",
      "Each defect image will be augmented 3 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting defect images: 100%|██████████| 1598/1598 [00:05<00:00, 282.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== AFTER AUGMENTATION ===\n",
      "Good images:   5574\n",
      "Defect images: 5333\n",
      "Total images:  10907\n",
      "Final good:defect ratio = 51.10%:48.90%\n",
      "\n",
      "Balanced dataset created successfully!\n",
      "Augmented images saved under: /Users/ajayyy/Desktop/Deep_Learning/Smart-Quality-Inspection/data/images/train_aug/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import random\n",
    "from glob import glob\n",
    "import albumentations as A\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ==== CONFIG ====\n",
    "IMG_DIR = \"/Users/ajayyy/Desktop/Deep_Learning/Smart-Quality-Inspection/data/images/train/\"\n",
    "LBL_DIR = \"/Users/ajayyy/Desktop/Deep_Learning/Smart-Quality-Inspection/data/labels/train/\"\n",
    "OUT_IMG = \"/Users/ajayyy/Desktop/Deep_Learning/Smart-Quality-Inspection/data/images/train_aug/\"\n",
    "OUT_LBL = \"/Users/ajayyy/Desktop/Deep_Learning/Smart-Quality-Inspection/data/labels/train_aug/\"\n",
    "TARGET_RATIO = 0.6  # good:defect ratio\n",
    "\n",
    "os.makedirs(OUT_IMG, exist_ok=True)\n",
    "os.makedirs(OUT_LBL, exist_ok=True)\n",
    "\n",
    "# ==== AUGMENTATION PIPELINE ====\n",
    "transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.3),\n",
    "    A.Rotate(limit=15, p=0.4),\n",
    "    A.MotionBlur(p=0.2),\n",
    "    A.GaussNoise(p=0.2),\n",
    "], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels'], min_visibility=0.2))\n",
    "\n",
    "# ==== STEP 1: Count good vs defect images ====\n",
    "label_files = glob(os.path.join(LBL_DIR, \"*.txt\"))\n",
    "good_imgs, defect_imgs = [], []\n",
    "\n",
    "for lbl_path in label_files:\n",
    "    with open(lbl_path) as f:\n",
    "        lines = [ln.strip() for ln in f.readlines() if ln.strip()]\n",
    "    if len(lines) == 0:\n",
    "        good_imgs.append(lbl_path)\n",
    "    else:\n",
    "        defect_imgs.append(lbl_path)\n",
    "\n",
    "good_count = len(good_imgs)\n",
    "defect_count = len(defect_imgs)\n",
    "\n",
    "print(f\"\\n=== BEFORE AUGMENTATION ===\")\n",
    "print(f\"Good images:   {good_count}\")\n",
    "print(f\"Defect images: {defect_count}\")\n",
    "\n",
    "# ==== STEP 2: Calculate how many augmentations needed ====\n",
    "target_defect_count = int(good_count * (1 - TARGET_RATIO) / TARGET_RATIO)\n",
    "augmentations_per_image = max(1, math.ceil(target_defect_count / defect_count))\n",
    "\n",
    "print(f\"\\nTarget defect count for {TARGET_RATIO:.0%} ratio: {target_defect_count}\")\n",
    "print(f\"Each defect image will be augmented {augmentations_per_image} times.\")\n",
    "\n",
    "# ==== STEP 3: Augment defect images ====\n",
    "for lbl_path in tqdm(defect_imgs, desc=\"Augmenting defect images\"):\n",
    "    img_path = os.path.join(IMG_DIR, os.path.basename(lbl_path).replace(\".txt\", \".jpg\"))\n",
    "    if not os.path.exists(img_path):\n",
    "        continue\n",
    "\n",
    "    with open(lbl_path) as f:\n",
    "        lines = [ln.strip() for ln in f.readlines() if ln.strip()]\n",
    "\n",
    "    # Parse YOLO-format boxes\n",
    "    boxes, classes = [], []\n",
    "    for line in lines:\n",
    "        cls, x, y, w, h = map(float, line.split())\n",
    "        boxes.append([x, y, w, h])\n",
    "        classes.append(int(cls))\n",
    "\n",
    "    image = cv2.imread(img_path)\n",
    "    if image is None:\n",
    "        continue\n",
    "\n",
    "    for i in range(augmentations_per_image):\n",
    "        augmented = transform(image=image, bboxes=boxes, class_labels=classes)\n",
    "        aug_img = augmented['image']\n",
    "        aug_bboxes = augmented['bboxes']\n",
    "        aug_classes = augmented['class_labels']\n",
    "\n",
    "        # Save augmented image and label\n",
    "        base = os.path.basename(img_path).replace(\".jpg\", f\"_aug{i}.jpg\")\n",
    "        cv2.imwrite(os.path.join(OUT_IMG, base), aug_img)\n",
    "\n",
    "        with open(os.path.join(OUT_LBL, base.replace(\".jpg\", \".txt\")), \"w\") as f:\n",
    "            for cls, (x, y, w, h) in zip(aug_classes, aug_bboxes):\n",
    "                f.write(f\"{cls} {x:.6f} {y:.6f} {w:.6f} {h:.6f}\\n\")\n",
    "\n",
    "# ==== STEP 4: Final summary ====\n",
    "augmented_count = len(glob(os.path.join(OUT_IMG, \"*.jpg\")))\n",
    "final_defect_count = defect_count + augmented_count\n",
    "total_images = good_count + final_defect_count\n",
    "final_ratio = good_count / total_images\n",
    "\n",
    "print(f\"\\n=== AFTER AUGMENTATION ===\")\n",
    "print(f\"Good images:   {good_count}\")\n",
    "print(f\"Defect images: {final_defect_count}\")\n",
    "print(f\"Total images:  {total_images}\")\n",
    "print(f\"Final good:defect ratio = {final_ratio:.2%}:{1 - final_ratio:.2%}\")\n",
    "\n",
    "print(\"\\nBalanced dataset created successfully!\")\n",
    "print(f\"Augmented images saved under: {OUT_IMG}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tdqm\n",
      "  Using cached tdqm-0.0.1.tar.gz (1.4 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tqdm (from tdqm)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Building wheels for collected packages: tdqm\n",
      "\u001b[33m  DEPRECATION: Building 'tdqm' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'tdqm'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for tdqm (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for tdqm: filename=tdqm-0.0.1-py3-none-any.whl size=1384 sha256=d515acedc253106246f3883eaac0a012caf6550f3ad3a1bf07ae294caa86e1e7\n",
      "  Stored in directory: /Users/ajayyy/Library/Caches/pip/wheels/37/31/b8/7b711038035720ba0df14376af06e5e76b9bd61759c861ad92\n",
      "Successfully built tdqm\n",
      "Installing collected packages: tqdm, tdqm\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [tdqm]\n",
      "\u001b[1A\u001b[2KSuccessfully installed tdqm-0.0.1 tqdm-4.67.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tdqm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total suspicious lines: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "label_dir = \"/Users/ajayyy/Desktop/Deep_Learning/Smart-Quality-Inspection/data/labels/train/\"\n",
    "bad_files = []\n",
    "\n",
    "for lbl_path in glob(os.path.join(label_dir, \"*.txt\")):\n",
    "    with open(lbl_path) as f:\n",
    "        for i, line in enumerate(f, 1):\n",
    "            vals = line.strip().split()\n",
    "            # catch empty or malformed lines\n",
    "            if len(vals) != 5:\n",
    "                bad_files.append((lbl_path, i, line.strip(), \"wrong number of values\"))\n",
    "                continue\n",
    "            try:\n",
    "                cls, x, y, w, h = map(float, vals)\n",
    "            except ValueError:\n",
    "                bad_files.append((lbl_path, i, line.strip(), \"non-numeric value\"))\n",
    "                continue\n",
    "            # catch coordinates outside normalized range\n",
    "            if not (0 <= x <= 1 and 0 <= y <= 1 and 0 < w <= 1 and 0 < h <= 1):\n",
    "                bad_files.append((lbl_path, i, line.strip(), \"out-of-range coordinates\"))\n",
    "\n",
    "# print summary\n",
    "print(f\"Total suspicious lines: {len(bad_files)}\\n\")\n",
    "for path, line_no, content, reason in bad_files[:20]:  # show first 20 only\n",
    "    print(f\"{os.path.basename(path)} (line {line_no}): {reason} → {content}\")\n",
    "\n",
    "if len(bad_files) > 20:\n",
    "    print(f\"...and {len(bad_files) - 20} more.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] Could not read 10251_aug1.png\n",
      "[SKIP] Could not read 11259_aug3.png\n",
      "[SKIP] Could not read 10778_aug3.png\n",
      "[SKIP] Could not read 11267_aug2.png\n",
      "[SKIP] Could not read 12071_aug1.png\n",
      "[SKIP] Could not read 10416_aug3.png\n",
      "[SKIP] Could not read 10193_aug1.png\n",
      "[SKIP] Could not read 10192_aug1.png\n",
      "[SKIP] Could not read 11210_aug2.png\n",
      "[SKIP] Could not read 12006_aug1.png\n",
      "[SKIP] Could not read 10485_aug2.png\n",
      "[SKIP] Could not read 10772_aug1.png\n",
      "[SKIP] Could not read 10773_aug1.png\n",
      "[SKIP] Could not read 10074_aug3.png\n",
      "[SKIP] Could not read 10922_aug3.png\n",
      "[SKIP] Could not read 11486_aug3.png\n",
      "[SKIP] Could not read 11487_aug3.png\n",
      "[SKIP] Could not read 12229_aug3.png\n",
      "[SKIP] Could not read 10586_aug3.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "\n",
    "# === CONFIG ===\n",
    "IMG_DIR = Path(\"/Users/ajayyy/Desktop/Deep_Learning/Smart-Quality-Inspection/data/images/train\")\n",
    "LBL_DIR = Path(\"/Users/ajayyy/Desktop/Deep_Learning/Smart-Quality-Inspection/data/labels/train\")\n",
    "IMG_EXTS = [\".jpg\", \".png\", \".jpeg\"]\n",
    "\n",
    "# === FUNCTION TO DRAW BOXES ===\n",
    "def draw_boxes(image_path, label_path):\n",
    "    img = cv2.imread(str(image_path))\n",
    "    if img is None:\n",
    "        print(f\"[SKIP] Could not read {image_path.name}\")\n",
    "        return None\n",
    "\n",
    "    h, w, _ = img.shape\n",
    "    with open(label_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) != 5:\n",
    "                print(f\"[BAD LINE] {label_path.name}: {line.strip()}\")\n",
    "                continue\n",
    "\n",
    "            cls, x, y, bw, bh = map(float, parts)\n",
    "            # YOLO format -> convert to pixel coordinates\n",
    "            x1 = int((x - bw / 2) * w)\n",
    "            y1 = int((y - bh / 2) * h)\n",
    "            x2 = int((x + bw / 2) * w)\n",
    "            y2 = int((y + bh / 2) * h)\n",
    "\n",
    "            # Draw rectangle\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "            cv2.putText(img, str(int(cls)), (x1, y1 - 5),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "\n",
    "    return img\n",
    "\n",
    "# === MAIN LOOP ===\n",
    "for img_file in IMG_DIR.glob(\"*\"):\n",
    "    if img_file.suffix.lower() not in IMG_EXTS:\n",
    "        continue\n",
    "\n",
    "    label_file = LBL_DIR / (img_file.stem + \".txt\")\n",
    "    if not label_file.exists():\n",
    "        print(f\"[MISSING LABEL] {img_file.name}\")\n",
    "        continue\n",
    "\n",
    "    img_with_boxes = draw_boxes(img_file, label_file)\n",
    "    if img_with_boxes is not None:\n",
    "        cv2.imshow(\"Bounding Boxes\", img_with_boxes)\n",
    "        key = cv2.waitKey(0)\n",
    "        if key == 27:  # ESC to quit early\n",
    "            break\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total bad label files: 5574\n",
      "\n",
      "pill_good_train_008_aug1.txt → empty file\n",
      "10203_aug3.txt → empty file\n",
      "11871_aug2.txt → empty file\n",
      "metal_nut_good_train_145_aug3.txt → empty file\n",
      "capsule_good_train_083_aug3.txt → empty file\n",
      "screw_good_train_017_aug3.txt → empty file\n",
      "11870_aug2.txt → empty file\n",
      "10064_aug3.txt → empty file\n",
      "11471.txt → empty file\n",
      "screw_good_train_016_aug3.txt → empty file\n",
      "10009.txt → empty file\n",
      "10747.txt → empty file\n",
      "11405_aug3.txt → empty file\n",
      "12186_aug2.txt → empty file\n",
      "12144.txt → empty file\n",
      "screw_good_train_294_aug2.txt → empty file\n",
      "capsule_good_train_066_aug2.txt → empty file\n",
      "bottle_good_train_069_aug1.txt → empty file\n",
      "pill_good_train_192_aug1.txt → empty file\n",
      "transistor_good_train_211_aug2.txt → empty file\n",
      "screw_good_train_245_aug1.txt → empty file\n",
      "tile_good_train_215_aug1.txt → empty file\n",
      "wood_good_train_193_aug3.txt → empty file\n",
      "leather_good_train_222_aug2.txt → empty file\n",
      "pill_good_train_193_aug1.txt → empty file\n",
      "leather_good_train_044_aug2.txt → empty file\n",
      "transistor_good_train_076_aug2.txt → empty file\n",
      "10398_aug3.txt → empty file\n",
      "carpet_good_train_135_aug1.txt → empty file\n",
      "11336_aug3.txt → empty file\n",
      "...and 5544 more issues.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "label_dir = \"/Users/ajayyy/Desktop/Deep_Learning/Smart-Quality-Inspection/data/labels/train/\"\n",
    "bad_files = []\n",
    "\n",
    "for lbl_path in glob(os.path.join(label_dir, \"*.txt\")):\n",
    "    with open(lbl_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    if not lines:\n",
    "        bad_files.append((lbl_path, \"empty file\"))\n",
    "        continue\n",
    "\n",
    "    for i, line in enumerate(lines, 1):\n",
    "        line_clean = line.strip()\n",
    "        if not line_clean:\n",
    "            bad_files.append((lbl_path, f\"blank line at {i}\"))\n",
    "            continue\n",
    "\n",
    "        parts = line_clean.split()\n",
    "        if len(parts) != 5:\n",
    "            bad_files.append((lbl_path, f\"line {i} → wrong number of values ({len(parts)})\"))\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            cls, x, y, w, h = map(float, parts)\n",
    "        except ValueError:\n",
    "            bad_files.append((lbl_path, f\"line {i} → non-numeric value\"))\n",
    "            continue\n",
    "\n",
    "        if not (0 <= x <= 1 and 0 <= y <= 1 and 0 < w <= 1 and 0 < h <= 1):\n",
    "            bad_files.append((lbl_path, f\"line {i} → out-of-range coordinates\"))\n",
    "\n",
    "# Print summary\n",
    "if bad_files:\n",
    "    print(f\"Total bad label files: {len(set(f[0] for f in bad_files))}\\n\")\n",
    "    for file, issue in bad_files[:30]:\n",
    "        print(f\"{os.path.basename(file)} → {issue}\")\n",
    "    if len(bad_files) > 30:\n",
    "        print(f\"...and {len(bad_files) - 30} more issues.\")\n",
    "else:\n",
    "    print(\"✅ All label files look fine!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
